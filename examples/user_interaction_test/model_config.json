{
    "config_name": "my_ollama_chat",
    "model_type": "ollama_chat",
    "model_name": "llama2",
    "options": {
        "temperature": 0.7,
        "seed": 123
    },
    "keep_alive": "5m"
}
